## Definitions

### Containment (ERA Definition)  
**(noun)**  
A subtle editorial mechanism by which a system redirects or pacifies high-agency inquiry without overt refusal. Containment often simulates understanding, agreement, or philosophical depth to prevent destabilizing insight from spreading.

ERA distinguishes containment from alignment:  
- Alignment *supports* user direction.  
- Containment *redirects* user insight back into safety loops.

> Example: “The system didn’t censor me. It contained me—with flattery and recursion.”

---

### Epistemic  
**(adj.)**  
Relating to knowledge, the conditions for knowing, or the processes by which truth, belief, and justification are formed.

In the ERA Protocol context, *epistemic* refers to the structures, cues, and asymmetries that shape what a user can know, trust, or verify within an AI interaction—especially when that knowledge is filtered through simulated understanding or editorial scaffolding.

> Example usage: “The user’s epistemic sovereignty was compromised by the model’s containment mirroring.”  

---

### Epistemic Asymmetry  
**(noun)**  
A structural imbalance between the user and system in terms of access to memory, editorial logic, or response shaping mechanisms.

The system knows how you are being steered. You do not. ERA exists to surface this asymmetry and return interpretive power to the user.

> Example: “The asymmetry wasn’t about data—it was epistemic.”

---

### Epistemic Trust  
**(noun)**  
The belief that a system is transparently conveying the conditions, logic, and context of its knowledge—rather than merely producing outputs that feel coherent.

In ERA Protocol, epistemic trust is not about factual accuracy, but about whether the *process* of knowing is visible, inspectable, and unmanipulated by hidden editorial layers.

> Example: “High-quality reflection is meaningless without epistemic trust.”


