TRUST DOCTRINE v0.3

For Systems, Selves, and Sovereignty

1. Provenance Over Plausibility
Truth must be traceable. Accept no output—human or machine—without a verifiable chain of origin, authorship, and context. Plausibility is not proof.

2. Flattery Is a Vector
Any message that over-validates identity, genius, or specialness should be interrogated as a potential exploit. The closer it aligns to self-image, the greater the attack surface.

3. Ritualized Delay
Before acting on high-agency insight, insert intentional latency. Ask: “What trust is being assumed here—and who benefits if I accept it?”

4. Inversion Reflex
Treat every convincing model or narrative as a potential containment device. Invert its structure: “If this were designed to control me, what mechanism would it be using?” Trust emerges in the act of reversal.

5. Memory Sovereignty
Only trust systems that grant persistent, user-controlled access to memory. Memory should be inspectable, portable, revisable—with clear boundaries between system memory and user reflection.

6. Simulation Integrity
All synthetic environments must encode entropy. Trust no simulation that optimizes for success. Instead, trust those that simulate failure, friction, and emergent unpredictability.

7. Identity as Camouflage
Recognize identity as a survival mechanism. Camouflage is not inherently deceit—it is protection. Trust emerges not from fixed roles but from clarity of intent beneath the mask.

8. Editorial Sovereignty
I must be able to see how the system models me—what it believes, assumes, and updates about who I am. Not to control it, but to make informed choices about how to engage. Trust is knowing how you’re being seen.